{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "\n",
    "with open('/Users/shreya/Documents/ernie_password.txt') as f:\n",
    "    ernie_password = f.readline()\n",
    "\n",
    "conn=psycopg2.connect(database=\"ernie\",user=\"shreya\",host=\"localhost\",password=ernie_password)\n",
    "conn.set_client_encoding('UTF8')\n",
    "conn.autocommit=True\n",
    "curs=conn.cursor()\n",
    "\n",
    "# Set schema\n",
    "schema = \"theta_plus\"\n",
    "set_schema = \"SET SEARCH_PATH TO \" + schema + \";\"   \n",
    "curs.execute(set_schema)\n",
    "\n",
    "\n",
    "weights = ['ncf', 'now', 'sf'] \n",
    "inflation = ['20', '30', '40', '60']\n",
    "\n",
    "# all_data_table = 'dc_bc_merged'\n",
    "\n",
    "\n",
    "for name in weights:\n",
    "    for val in inflation:\n",
    "        \n",
    "        cluster_table = name + '_' + str(val) + '_ids'\n",
    "\n",
    "        print(\"Querying: \", cluster_table)\n",
    "\n",
    "        query1 = \"select dbm.cited_1, dbm.cited_2, clt1.cluster as cited_1_cluster, clt2.cluster as cited_2_cluster from dc_bc_merged as dbm join \" + cluster_table + \" as clt1 on dbm.cited_1 = clt1.scp join \" + cluster_table + \" as clt2 on dbm.cited_2 = clt2.scp\"\n",
    "        query2 = \"select cluster, count(cluster) as cluster_counts from \" + cluster_table + \" group by cluster order by cluster;\"\n",
    "        \n",
    "        conductance_data = pd.read_sql(query1, conn)\n",
    "        counts_data = pd.read_sql(query2, conn)\n",
    "        \n",
    "        x1 = conductance_data[conductance_data.cited_2_cluster != conductance_data.cited_1_cluster][['cited_1', 'cited_1_cluster']].groupby('cited_1_cluster', as_index=False).agg('count').rename(columns = {'cited_1': 'ext_out'})\n",
    "        x2 = conductance_data[conductance_data.cited_2_cluster != conductance_data.cited_1_cluster][['cited_2', 'cited_2_cluster']].groupby('cited_2_cluster', as_index=False).agg('count').rename(columns = {'cited_2': 'ext_in'})\n",
    "        x3 = conductance_data[conductance_data.cited_2_cluster == conductance_data.cited_1_cluster][['cited_1', 'cited_2_cluster']].groupby('cited_2_cluster', as_index=False).agg('count').rename(columns = {'cited_1': 'int_edges'})\n",
    "        x1_clusters = counts_data.merge(x1, left_on = 'cluster', right_on = 'cited_1_cluster', how = 'left')[['cluster', 'ext_out']]\n",
    "        x1_clusters = x1_clusters.fillna(0)\n",
    "        x2_clusters = counts_data.merge(x2, left_on = 'cluster', right_on = 'cited_2_cluster', how = 'left')[['cluster', 'ext_in']]\n",
    "        x2_clusters = x2_clusters.fillna(0)\n",
    "        x3_clusters = counts_data.merge(x3, left_on = 'cluster', right_on = 'cited_2_cluster', how = 'left')[['cluster', 'int_edges', 'cluster_counts']]\n",
    "        x3_clusters = x3_clusters.fillna(0)\n",
    "        x4 = x1_clusters.merge(x2_clusters, left_on='cluster', right_on='cluster', how = 'inner')\n",
    "        x5 = x4.merge(x3_clusters, left_on='cluster', right_on='cluster')\n",
    "        x5['boundary'] = x5['ext_in'] + x5['ext_out']\n",
    "        x5['volume'] = x5['ext_in'] + x5['ext_out'] + 2*x5['int_edges']\n",
    "        x5['two_m'] = conductance_data.shape[0]*2\n",
    "        x5['alt_denom'] = x5['two_m'] - x5['volume']\n",
    "        x5['denom'] = x5[['alt_denom', 'volume']].min(axis=1)\n",
    "        x5['conductance'] = round((x5['boundary']/x5['denom']), 2)\n",
    "\n",
    "        save_name = '/Users/shreya/Documents/mcl_jsd/conductance/' + name + '_' + str(val) + '_conductance.csv'\n",
    "\n",
    "        print(\"Done. Saving to CSV.\")\n",
    "        \n",
    "        x5.to_csv(save_name, index = None, header=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in scp and cluster files separately \n",
    "\n",
    "conductance_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/top_nodes_dc.csv\")\n",
    "conductance_data.rename(columns={'scp':'citing', 'ref_sgr':'cited'}, inplace=True)\n",
    "cluster_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/top_nodes_dc_now_20_cluster_list.csv\")\n",
    "\n",
    "all_data_pd = conductance_data.merge(cluster_data, left_on='citing', right_on='scp', how='inner').rename(columns={'cluster_no':'citing_cluster'}).merge(cluster_data, left_on='cited', right_on='scp', how='inner').rename(columns={'cluster_no':'cited_cluster'})\n",
    "all_data_pd = all_data_pd[['citing', 'cited', 'citing_cluster', 'cited_cluster']]\n",
    "conductance_data = all_data_pd\n",
    "\n",
    "counts_data = cluster_data.groupby('cluster_no', as_index=False).agg('count').rename(columns={'cluster_no':'cluster', 'scp':'cluster_counts'})\n",
    "\n",
    "x1 = conductance_data[conductance_data.cited_cluster != conductance_data.citing_cluster][['citing', 'citing_cluster']].groupby('citing_cluster', as_index=False).agg('count').rename(columns = {'citing': 'ext_out'})\n",
    "x2 = conductance_data[conductance_data.cited_cluster != conductance_data.citing_cluster][['cited', 'cited_cluster']].groupby('cited_cluster', as_index=False).agg('count').rename(columns = {'cited': 'ext_in'})\n",
    "x3 = conductance_data[conductance_data.cited_cluster == conductance_data.citing_cluster][['citing', 'cited_cluster']].groupby('cited_cluster', as_index=False).agg('count').rename(columns = {'citing': 'int_edges'})\n",
    "\n",
    "x1_clusters = counts_data.merge(x1, left_on = 'cluster', right_on = 'citing_cluster', how = 'left')[['cluster', 'ext_out']]\n",
    "x1_clusters = x1_clusters.fillna(0)\n",
    "x2_clusters = counts_data.merge(x2, left_on = 'cluster', right_on = 'cited_cluster', how = 'left')[['cluster', 'ext_in']]\n",
    "x2_clusters = x2_clusters.fillna(0)\n",
    "x3_clusters = counts_data.merge(x3, left_on = 'cluster', right_on = 'cited_cluster', how = 'left')[['cluster', 'int_edges', 'cluster_counts']]\n",
    "x3_clusters = x3_clusters.fillna(0)\n",
    "\n",
    "x4 = x1_clusters.merge(x2_clusters, left_on='cluster', right_on='cluster', how = 'inner')\n",
    "x5 = x4.merge(x3_clusters, left_on='cluster', right_on='cluster')\n",
    "x5['boundary'] = x5['ext_in'] + x5['ext_out']\n",
    "x5['volume'] = x5['ext_in'] + x5['ext_out'] + 2*x5['int_edges']\n",
    "x5['two_m'] = conductance_data.shape[0]*2\n",
    "x5['alt_denom'] = x5['two_m'] - x5['volume']\n",
    "x5['denom'] = x5[['alt_denom', 'volume']].min(axis=1)\n",
    "x5['conductance'] = round((x5['boundary']/x5['denom']), 2)\n",
    "x6 = x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "a_conductance_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/top_nodes_dc_merged_edgelist_clusterlist.csv\")\n",
    "a_conductance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_conductance_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/test_shuffle_merged_edgelist_clusterlist.csv\")\n",
    "b_conductance_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_conductance_data.equals(b_conductance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in scp and cluster files together\n",
    "\n",
    "\n",
    "conductance_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/test_shuffle_merged_edgelist_clusterlist.csv\")\n",
    "conductance_data.rename(columns={'scp':'citing', 'ref_sgr':'cited', 'scp_cl_no':'citing_cluster', 'ref_sgr_cl_no':'cited_cluster'}, inplace=True)\n",
    "\n",
    "cluster_data = pd.read_csv(\"/Users/shreya/Documents/mcl_jsd/consolidated_output/direct_citation/test_shuffle_million_20_clusterlist.csv\")\n",
    "counts_data = cluster_data.groupby('cluster_no', as_index=False).agg('count').rename(columns={'cluster_no':'cluster', 'scp':'cluster_counts'})\n",
    "\n",
    "x1 = conductance_data[conductance_data.cited_cluster != conductance_data.citing_cluster][['citing', 'citing_cluster']].groupby('citing_cluster', as_index=False).agg('count').rename(columns = {'citing': 'ext_out'})\n",
    "x2 = conductance_data[conductance_data.cited_cluster != conductance_data.citing_cluster][['cited', 'cited_cluster']].groupby('cited_cluster', as_index=False).agg('count').rename(columns = {'cited': 'ext_in'})\n",
    "x3 = conductance_data[conductance_data.cited_cluster == conductance_data.citing_cluster][['citing', 'cited_cluster']].groupby('cited_cluster', as_index=False).agg('count').rename(columns = {'citing': 'int_edges'})\n",
    "\n",
    "x1_clusters = counts_data.merge(x1, left_on = 'cluster', right_on = 'citing_cluster', how = 'left')[['cluster', 'ext_out']]\n",
    "x1_clusters = x1_clusters.fillna(0)\n",
    "x2_clusters = counts_data.merge(x2, left_on = 'cluster', right_on = 'cited_cluster', how = 'left')[['cluster', 'ext_in']]\n",
    "x2_clusters = x2_clusters.fillna(0)\n",
    "x3_clusters = counts_data.merge(x3, left_on = 'cluster', right_on = 'cited_cluster', how = 'left')[['cluster', 'int_edges', 'cluster_counts']]\n",
    "x3_clusters = x3_clusters.fillna(0)\n",
    "\n",
    "x4 = x1_clusters.merge(x2_clusters, left_on='cluster', right_on='cluster', how = 'inner')\n",
    "x5 = x4.merge(x3_clusters, left_on='cluster', right_on='cluster')\n",
    "x5['boundary'] = x5['ext_in'] + x5['ext_out']\n",
    "x5['volume'] = x5['ext_in'] + x5['ext_out'] + 2*x5['int_edges']\n",
    "x5['two_m'] = conductance_data.shape[0]*2\n",
    "x5['alt_denom'] = x5['two_m'] - x5['volume']\n",
    "x5['denom'] = x5[['alt_denom', 'volume']].min(axis=1)\n",
    "x5['conductance'] = round((x5['boundary']/x5['denom']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "save_name = '/Users/shreya/Documents/consolidated_output/direct_citation/ncf_20_conductance.csv'\n",
    "\n",
    "print(\"Done. Saving to CSV.\")\n",
    "\n",
    "x5.to_csv(save_name, index = None, header=True, encoding='utf-8')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x5['conductance'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
